DATASET_PATHS=[
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/ldm-text2im-large-256/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/ldm-t2i'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/stable-diffusion-v1-4/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/sd14'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/stable-diffusion-v1-5/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/sd15'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/stable-diffusion-2-1/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/sd21'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/stable-diffusion-xl-base-1.0/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/sdxl'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/stable-diffusion-xl-refiner-1.0/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/sdxl-refiner'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/sd-turbo/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/sd-turbo'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/sdxl-turbo/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/sdxl-turbo'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/lcm-lora-sdv1-5/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/lcm-sd15'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/lcm-lora-sdxl/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/lcm-sdxl'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/sd-controlnet-canny/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/sd-cn'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/sd21-controlnet-canny/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/sd21-cn'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/controlnet-canny-sdxl-1.0/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/sdxl-cn'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/stable-diffusion-inpainting/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/sd-inpainting'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/stable-diffusion-2-inpainting/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/sd21-inpainting'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/DRCT-2M/stable-diffusion-xl-1.0-inpainting-0.1/val2017', 'data_mode': 'ours', 'key': 'DRCT-2M/sdxl-inpainting'},

    {'real_path': '/root/autodl-tmp/AIGC_data/GenImage/Midjourney/val/nature', 'fake_path': '/root/autodl-tmp/AIGC_data/GenImage/Midjourney/val/ai', 'data_mode': 'ours', 'key': 'GenImage/Midjourney'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/GenImage/stable_diffusion_v_1_4/val/nature', 'fake_path': '/root/autodl-tmp/AIGC_data/GenImage/stable_diffusion_v_1_4/val/ai', 'data_mode': 'ours', 'key': 'GenImage/sd14'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/GenImage/stable_diffusion_v_1_5/val/nature', 'fake_path': '/root/autodl-tmp/AIGC_data/GenImage/stable_diffusion_v_1_5/val/ai', 'data_mode': 'ours', 'key': 'GenImage/sd15'}, 

    {'real_path': '/root/autodl-tmp/AIGC_data/GenImage/ADM/val/nature', 'fake_path': '/root/autodl-tmp/AIGC_data/GenImage/ADM/val/ai', 'data_mode': 'ours', 'key': 'GenImage/ADM'}, 

    {'real_path': '/root/autodl-tmp/AIGC_data/GenImage/glide/val/nature', 'fake_path': '/root/autodl-tmp/AIGC_data/GenImage/glide/val/ai', 'data_mode': 'ours', 'key': 'GenImage/glide'}, 

    {'real_path': '/root/autodl-tmp/AIGC_data/GenImage/wukong/val/nature', 'fake_path': '/root/autodl-tmp/AIGC_data/GenImage/wukong/val/ai', 'data_mode': 'ours', 'key': 'GenImage/wukong'}, 

    {'real_path': '/root/autodl-tmp/AIGC_data/GenImage/VQDM/val/nature', 'fake_path': '/root/autodl-tmp/AIGC_data/GenImage/VQDM/val/ai', 'data_mode': 'ours', 'key': 'GenImage/VQDM'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/GenImage/BigGAN/val/nature', 'fake_path': '/root/autodl-tmp/AIGC_data/GenImage/BigGAN/val/ai', 'data_mode': 'ours', 'key': 'GenImage/BigGAN'}, 
        
    {'real_path': '/root/autodl-tmp/AIGC_data/Chameleon/test/0_real', 'fake_path': '/root/autodl-tmp/AIGC_data/Chameleon/test/1_fake', 'data_mode': 'ours', 'key': 'Chameleon'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/Eval_GEN/Flux', 'data_mode': 'ours', 'key': 'Eval_GEN/Flux'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/Eval_GEN/GoT', 'data_mode': 'ours', 'key': 'Eval_GEN/GoT'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/Eval_GEN/Infinity', 'data_mode': 'ours', 'key': 'Eval_GEN/Infinity'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/Eval_GEN/OmniGen', 'data_mode': 'ours', 'key': 'Eval_GEN/OmniGen'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/Eval_GEN/NOVA', 'data_mode': 'ours', 'key': 'Eval_GEN/NOVA'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/Eval_GEN/sd14', 'data_mode': 'ours', 'key': 'Eval_GEN/sd14'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/Eval_GEN/sdxl', 'data_mode': 'ours', 'key': 'Eval_GEN/sdxl'}, 
    
    {'real_path': '/root/autodl-tmp/AIGC_data/MSCOCO/val2017', 'fake_path': '/root/autodl-tmp/AIGC_data/GPT-ImgEval', 'data_mode': 'ours', 'key': 'GPT-ImgEval'}
    
]

import torchvision.transforms as transforms
import numpy as np

from torch.utils.data import Dataset
from scipy.ndimage.filters import gaussian_filter

import pickle
import os
from io import BytesIO
from PIL import Image 
import random

MEAN = {
    "imagenet":[0.485, 0.456, 0.406],
    "clip":[0.48145466, 0.4578275, 0.40821073]
}

STD = {
    "imagenet":[0.229, 0.224, 0.225],
    "clip":[0.26862954, 0.26130258, 0.27577711]
}

def png2jpg(img, quality):
    out = BytesIO()
    img.save(out, format='jpeg', quality=quality) # ranging from 0-95, 75 is default
    img = Image.open(out)
    # load from memory before ByteIO closes
    img = np.array(img)
    out.close()
    return Image.fromarray(img)


def gaussian_blur(img, sigma):
    img = np.array(img)

    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)
    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)
    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)

    return Image.fromarray(img)

def recursively_read(rootdir, must_contain, exts=["PNG", "png", "jpg", "JPEG", "jpeg", "bmp"]):
    out = [] 
    for r, d, f in os.walk(rootdir):
        for file in f:
            if (file.split('.')[1] in exts)  and  (must_contain in os.path.join(r, file)):
                out.append(os.path.join(r, file))
    return out


def get_list(path, must_contain='', eval_gen=False):
    if ".pickle" in path:
        with open(path, 'rb') as f:
            image_list = pickle.load(f)
        image_list = [ item for item in image_list if must_contain in item   ]
    else:
        image_list = recursively_read(path, must_contain)
        if eval_gen:
            image_list = [item for item in image_list if '0' in os.path.basename(item)]
    return image_list

class RealFakeDataset(Dataset):
    def __init__(self,  real_path, 
                        fake_path, 
                        data_mode, 
                        max_sample,
                        arch,
                        jpeg_quality=None,
                        gaussian_sigma=None,
                        resolution_thres=None,
                        key=None):

        # assert data_mode in ["wang2020", "ours"]
        self.jpeg_quality = jpeg_quality
        self.gaussian_sigma = gaussian_sigma
        self.resolution_thres = resolution_thres

        self.key = key
        
        # = = = = = = data path = = = = = = = = = # 
        if type(real_path) == str and type(fake_path) == str:
            real_list, fake_list = self.read_path(real_path, fake_path, data_mode, max_sample)
        else:
            real_list = []
            fake_list = []
            for real_p, fake_p in zip(real_path, fake_path):
                real_l, fake_l = self.read_path(real_p, fake_p, data_mode, max_sample)
                real_list += real_l
                fake_list += fake_l

        self.total_list = real_list + fake_list


        # = = = = = =  label = = = = = = = = = # 

        self.labels_dict = {}
        for i in real_list:
            self.labels_dict[i] = 0
        for i in fake_list:
            self.labels_dict[i] = 1

        stat_from = "imagenet" if arch.lower().startswith("imagenet") else "clip"
        self.transform = transforms.Compose([
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize( mean=MEAN[stat_from], std=STD[stat_from] ),
        ])


    def read_path(self, real_path, fake_path, data_mode, max_sample):

        is_eval_gen = self.key is not None and 'Eval_GEN' in self.key

        if data_mode == 'wang2020':
            real_list = get_list(real_path, must_contain='0_real')
            fake_list = get_list(fake_path, must_contain='1_fake')
        else:
            real_list = get_list(real_path)
            fake_list = []
            fake_path_list = fake_path.split(",")
            for fake_path in fake_path_list:
                fake_list += get_list(fake_path, eval_gen=is_eval_gen)


        if max_sample is not None:
            if (max_sample <= len(real_list)):
                random.shuffle(real_list)
                real_list = real_list[0:max_sample]

            if max_sample <= len(fake_list):
                random.shuffle(fake_list)
                fake_list = fake_list[0:max_sample]


        # assert len(real_list) == len(fake_list)  

        return real_list, fake_list



    def __len__(self):
        return len(self.total_list)

    def __getitem__(self, idx):
        
        img_path = self.total_list[idx]

        label = self.labels_dict[img_path]
        img = Image.open(img_path).convert("RGB")

        if self.gaussian_sigma is not None:
            img = gaussian_blur(img, self.gaussian_sigma) 
        if self.jpeg_quality is not None:
            img = png2jpg(img, self.jpeg_quality)

        img = self.transform(img)
        return img, label